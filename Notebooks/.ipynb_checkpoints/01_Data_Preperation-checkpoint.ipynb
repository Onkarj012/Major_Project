{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a3ad6c-15cf-4e1d-b098-b927a38f4317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for HDFCBANK.NS in ./Data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/fpgn89657rz0ls823nzpm4hh0000gn/T/ipykernel_9529/958578041.py:168: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  prev_pl = sub_piv[sub_piv.index < recent_ph][sub_piv['pivot_low']].index.max()\n"
     ]
    }
   ],
   "source": [
    "# core_data_pipeline.py\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: EMA and Wilder EMA\n",
    "# -----------------------------\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    k = 2 / (span + 1)\n",
    "    return series.ewm(alpha=k, adjust=False).mean()\n",
    "\n",
    "def wilder_ema(series: pd.Series, period: int) -> pd.Series:\n",
    "    # Wilder smoothing = previous + (1/period)*(current - previous)\n",
    "    return series.ewm(alpha=1/period, adjust=False).mean()\n",
    "\n",
    "# -----------------------------\n",
    "# RSI (Wilder, default 14)\n",
    "# -----------------------------\n",
    "def rsi_wilder(close: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    avg_up = wilder_ema(up, period)\n",
    "    avg_down = wilder_ema(down, period)\n",
    "    rs = avg_up / (avg_down.replace(0, np.nan))\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi.fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# MACD (12, 26, 9)\n",
    "# -----------------------------\n",
    "def macd(close: pd.Series, fast=12, slow=26, signal=9):\n",
    "    ema_fast = ema(close, fast)\n",
    "    ema_slow = ema(close, slow)\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = ema(macd_line, signal)\n",
    "    hist = macd_line - signal_line\n",
    "    return macd_line, signal_line, hist\n",
    "\n",
    "# -----------------------------\n",
    "# Bollinger Bands (20, 2)\n",
    "# -----------------------------\n",
    "def bollinger_bands(close: pd.Series, period=20, mult=2.0):\n",
    "    sma = close.rolling(period).mean()\n",
    "    std = close.rolling(period).std()\n",
    "    upper = sma + mult * std\n",
    "    lower = sma - mult * std\n",
    "    return sma, upper, lower\n",
    "\n",
    "# -----------------------------\n",
    "# ATR (Wilder, default 14)\n",
    "# -----------------------------\n",
    "def true_range(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:\n",
    "    prev_close = close.shift(1)\n",
    "    tr1 = high - low\n",
    "    tr2 = (high - prev_close).abs()\n",
    "    tr3 = (low - prev_close).abs()\n",
    "    return pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "\n",
    "def atr_wilder(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:\n",
    "    tr = true_range(high, low, close)\n",
    "    return wilder_ema(tr, period)\n",
    "\n",
    "# -----------------------------\n",
    "# Pivot Points (Classic) from previous day\n",
    "# -----------------------------\n",
    "def daily_pivot_levels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # expects daily data; compute pivots from previous day’s HLC\n",
    "    piv = pd.DataFrame(index=df.index)\n",
    "    H, L, C = df['High'].shift(1), df['Low'].shift(1), df['Close'].shift(1)\n",
    "    P = (H + L + C) / 3.0\n",
    "    R1 = 2*P - L\n",
    "    S1 = 2*P - H\n",
    "    R2 = P + (H - L)\n",
    "    S2 = P - (H - L)\n",
    "    piv['P'] = P\n",
    "    piv['R1'] = R1\n",
    "    piv['S1'] = S1\n",
    "    piv['R2'] = R2\n",
    "    piv['S2'] = S2\n",
    "    return piv\n",
    "\n",
    "# -----------------------------\n",
    "# Fractal pivots (swing highs/lows)\n",
    "# -----------------------------\n",
    "def fractal_pivots(df: pd.DataFrame, left=2, right=2):\n",
    "    highs = df['High'].values\n",
    "    lows = df['Low'].values\n",
    "    n = len(df)\n",
    "    pivot_high = np.full(n, False, dtype=bool)\n",
    "    pivot_low = np.full(n, False, dtype=bool)\n",
    "    for i in range(left, n-right):\n",
    "        if highs[i] == max(highs[i-left:i+right+1]):\n",
    "            pivot_high[i] = True\n",
    "        if lows[i] == min(lows[i-left:i+right+1]):\n",
    "            pivot_low[i] = True\n",
    "    piv = pd.DataFrame({'pivot_high': pivot_high, 'pivot_low': pivot_low}, index=df.index)\n",
    "    piv['ph_price'] = np.where(piv['pivot_high'], df['High'], np.nan)\n",
    "    piv['pl_price'] = np.where(piv['pivot_low'], df['Low'], np.nan)\n",
    "    return piv\n",
    "\n",
    "# -----------------------------\n",
    "# Clustered Support/Resistance from pivots\n",
    "# -----------------------------\n",
    "def cluster_levels(prices: pd.Series, tolerance_frac=0.002, min_touches=3):\n",
    "    # tolerance_frac is fraction of price (e.g., 0.2%) for clustering\n",
    "    pts = prices.dropna().sort_values().values\n",
    "    if len(pts) == 0:\n",
    "        return []\n",
    "    clusters = [[pts[0]]]\n",
    "    for p in pts[1:]:\n",
    "        if abs(p - clusters[-1][-1]) <= tolerance_frac * clusters[-1][-1]:\n",
    "            clusters[-1].append(p)\n",
    "        else:\n",
    "            clusters.append([p])\n",
    "    levels = []\n",
    "    for cl in clusters:\n",
    "        if len(cl) >= min_touches:\n",
    "            levels.append({'level': float(np.mean(cl)), 'touches': int(len(cl))})\n",
    "    return levels\n",
    "\n",
    "def support_resistance_from_fractals(df: pd.DataFrame, piv: pd.DataFrame, atr_col='ATR', atr_mult=0.0, min_touches=3):\n",
    "    # optional ATR-based tolerance: tolerance = atr_mult * ATR; else percentage based handled externally\n",
    "    sr = {}\n",
    "    if atr_mult > 0 and atr_col in df.columns:\n",
    "        tol_series = atr_mult * df[atr_col]\n",
    "        # create price list with atr-specific tolerance per bar is more advanced;\n",
    "        # for now we’ll apply percentage-based outside this function\n",
    "    highs = piv['ph_price']\n",
    "    lows = piv['pl_price']\n",
    "    res_levels = cluster_levels(highs, tolerance_frac=0.002, min_touches=min_touches)\n",
    "    sup_levels = cluster_levels(lows, tolerance_frac=0.002, min_touches=min_touches)\n",
    "    sr['resistance'] = res_levels\n",
    "    sr['support'] = sup_levels\n",
    "    return sr\n",
    "\n",
    "# -----------------------------\n",
    "# Fibonacci retracements\n",
    "# -----------------------------\n",
    "def fib_levels_from_swings(swing_high: float, swing_low: float):\n",
    "    ratios = [0.236, 0.382, 0.5, 0.618, 0.786]\n",
    "    if swing_high >= swing_low:\n",
    "        diff = swing_high - swing_low\n",
    "        levels = {f'{int(r*100)}%': swing_high - r*diff for r in ratios}\n",
    "        levels['0%'] = swing_high\n",
    "        levels['100%'] = swing_low\n",
    "    else:\n",
    "        diff = swing_low - swing_high\n",
    "        levels = {f'{int(r*100)}%': swing_low + r*diff for r in ratios}\n",
    "        levels['0%'] = swing_low\n",
    "        levels['100%'] = swing_high\n",
    "    return levels\n",
    "\n",
    "def last_swing_from_fractals(df: pd.DataFrame, piv: pd.DataFrame, lookback=200):\n",
    "    sub = df.tail(lookback)\n",
    "    sub_piv = piv.loc[sub.index]\n",
    "    # pick most recent pivot (high or low), then prior opposite\n",
    "    last_idx = sub.index[-1]\n",
    "    # find most recent pivot high or low\n",
    "    recent_ph = sub_piv[sub_piv['pivot_high']].index.max()\n",
    "    recent_pl = sub_piv[sub_piv['pivot_low']].index.max()\n",
    "    if pd.isna(recent_ph) and pd.isna(recent_pl):\n",
    "        return None, None\n",
    "    if pd.isna(recent_pl) or (recent_ph and recent_ph > recent_pl):\n",
    "        # last was a pivot high; find the preceding pivot low\n",
    "        prev_pl = sub_piv[sub_piv.index < recent_ph][sub_piv['pivot_low']].index.max()\n",
    "        if pd.isna(prev_pl):\n",
    "            return None, None\n",
    "        return float(df.loc[recent_ph, 'High']), float(df.loc[prev_pl, 'Low'])\n",
    "    else:\n",
    "        # last was a pivot low; find preceding pivot high\n",
    "        prev_ph = sub_piv[sub_piv.index < recent_pl][sub_piv['pivot_high']].index.max()\n",
    "        if pd.isna(prev_ph):\n",
    "            return None, None\n",
    "        return float(df.loc[prev_ph, 'High']), float(df.loc[recent_pl, 'Low'])\n",
    "\n",
    "# -----------------------------\n",
    "# Fetch and assemble feature set\n",
    "# -----------------------------\n",
    "def fetch_ohlcv(symbol: str, period=\"5y\", interval=\"1d\") -> pd.DataFrame:\n",
    "    t = yf.Ticker(symbol)\n",
    "    df = t.history(period=period, interval=interval, auto_adjust=False)\n",
    "    df = df.rename(columns=str.title)\n",
    "    df = df[['Open','High','Low','Close','Volume']].dropna()\n",
    "    return df\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out['RSI14'] = rsi_wilder(out['Close'], 14)\n",
    "    macd_line, signal_line, hist = macd(out['Close'], 12, 26, 9)\n",
    "    out['MACD'] = macd_line\n",
    "    out['MACD_SIGNAL'] = signal_line\n",
    "    out['MACD_HIST'] = hist\n",
    "    sma20, bb_u, bb_l = bollinger_bands(out['Close'], 20, 2.0)\n",
    "    out['BB_MID_20'] = sma20\n",
    "    out['BB_UPPER_20_2'] = bb_u\n",
    "    out['BB_LOWER_20_2'] = bb_l\n",
    "    out['ATR14'] = atr_wilder(out['High'], out['Low'], out['Close'], 14)\n",
    "    piv = daily_pivot_levels(out)\n",
    "    out = out.join(piv)\n",
    "    pivots = fractal_pivots(out, left=2, right=2)\n",
    "    out = out.join(pivots)\n",
    "    # Basic S/R summary (not columns): return as metadata\n",
    "    sr = support_resistance_from_fractals(out, pivots, atr_col='ATR14', atr_mult=0.0, min_touches=3)\n",
    "    # Fibonacci levels from last swing\n",
    "    sh, sl = last_swing_from_fractals(out, pivots, lookback=200)\n",
    "    fib = fib_levels_from_swings(sh, sl) if (sh is not None and sl is not None) else {}\n",
    "    return out, sr, fib\n",
    "\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbols = [\"HDFCBANK.NS\"]\n",
    "\n",
    "    # ensure data folder exists\n",
    "    data_dir = \"Projects/Major_Project/Data\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    for s in symbols:\n",
    "        df = fetch_ohlcv(s, period=\"5y\", interval=\"1d\")\n",
    "        feats, sr, fib = build_features(df)\n",
    "\n",
    "        # save features CSV\n",
    "        feats_path = os.path.join(data_dir, f\"{s}_features.csv\")\n",
    "        feats.to_csv(feats_path, index=True)\n",
    "\n",
    "        # save support levels CSV\n",
    "        support_path = os.path.join(data_dir, f\"{s}_support_levels.csv\")\n",
    "        pd.DataFrame(sr.get('support', [])).to_csv(support_path, index=False)\n",
    "\n",
    "        # save resistance levels CSV\n",
    "        resistance_path = os.path.join(data_dir, f\"{s}_resistance_levels.csv\")\n",
    "        pd.DataFrame(sr.get('resistance', [])).to_csv(resistance_path, index=False)\n",
    "\n",
    "        # save Fibonacci levels CSV\n",
    "        fib_path = os.path.join(data_dir, f\"{s}_fibonacci_levels.csv\")\n",
    "        pd.Series(fib).to_csv(fib_path, index=True)\n",
    "\n",
    "        print(f\"Saved data for {s} in {data_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d44d70-2ab4-48aa-aaec-3973bddd24ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
