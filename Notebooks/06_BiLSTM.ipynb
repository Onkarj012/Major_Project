{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a8de83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Stocks Loaded: 57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nifty50_stocks = [\n",
    "    \"ADANIENT.NS\", \"ADANIPORTS.NS\", \"APOLLOHOSP.NS\", \"ASIANPAINT.NS\", \"AXISBANK.NS\",\n",
    "    \"BAJAJ-AUTO.NS\", \"BAJAJFINSV.NS\", \"BAJFINANCE.NS\", \"BHARTIARTL.NS\", \"BPCL.NS\",\n",
    "    \"BRITANNIA.NS\", \"CIPLA.NS\", \"COALINDIA.NS\", \"DIVISLAB.NS\", \"DRREDDY.NS\",\n",
    "    \"EICHERMOT.NS\", \"GRASIM.NS\", \"HCLTECH.NS\", \"HDFC.NS\", \"HDFCBANK.NS\",\n",
    "    \"HDFCLIFE.NS\", \"HEROMOTOCO.NS\", \"HINDALCO.NS\", \"HINDUNILVR.NS\", \"ICICIBANK.NS\",\n",
    "    \"INDUSINDBK.NS\", \"INFY.NS\", \"ITC.NS\", \"JSWSTEEL.NS\", \"KOTAKBANK.NS\",\n",
    "    \"LT.NS\", \"M&M.NS\", \"MARUTI.NS\", \"NESTLEIND.NS\", \"NTPC.NS\",\n",
    "    \"ONGC.NS\", \"POWERGRID.NS\", \"RELIANCE.NS\", \"SBILIFE.NS\", \"SHREECEM.NS\",\n",
    "    \"SUNPHARMA.NS\", \"TATACONSUM.NS\", \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TCS.NS\",\n",
    "    \"TECHM.NS\", \"TITAN.NS\", \"ULTRACEMCO.NS\", \"UPL.NS\", \"WIPRO.NS\"\n",
    "]\n",
    "\n",
    "banknifty_stocks = [\n",
    "    \"AXISBANK.NS\", \"BANDHANBNK.NS\", \"BANKBARODA.NS\", \"CANBK.NS\", \"FEDERALBNK.NS\",\n",
    "    \"HDFCBANK.NS\", \"ICICIBANK.NS\", \"IDFCFIRSTB.NS\", \"INDUSINDBK.NS\", \"KOTAKBANK.NS\",\n",
    "    \"PNB.NS\", \"SBIN.NS\"\n",
    "]\n",
    "\n",
    "all_stocks = list(set(nifty50_stocks + banknifty_stocks))\n",
    "print(f\"Total Stocks Loaded: {len(all_stocks)}\")\n",
    "pd.DataFrame(all_stocks, columns=[\"Stock\"]).to_csv(\"../Data/fundamental/all_stocks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b488a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def fetch_fundamental_data(stock):\n",
    "    try:\n",
    "        ticker = yf.Ticker(stock)\n",
    "        balance_sheet_q = ticker.quarterly_balance_sheet.T\n",
    "        income_statement_q = ticker.quarterly_financials.T\n",
    "        cashflow_q = ticker.quarterly_cashflow.T\n",
    "        balance_sheet_a = ticker.balance_sheet.T\n",
    "        income_statement_a = ticker.financials.T\n",
    "        cashflow_a = ticker.cashflow.T\n",
    "        info = ticker.info\n",
    "\n",
    "        net_income = info.get(\"netIncomeToCommon\")\n",
    "        book_value_per_share = info.get(\"bookValue\")\n",
    "        shares_outstanding = info.get(\"sharesOutstanding\")\n",
    "        total_equity = book_value_per_share * shares_outstanding if book_value_per_share and shares_outstanding else None\n",
    "        market_cap = info.get(\"marketCap\")\n",
    "        total_debt = info.get(\"totalDebt\", 0)\n",
    "        total_assets = info.get(\"totalAssets\")\n",
    "\n",
    "        roe = (net_income / total_equity) * 100 if net_income and total_equity else None\n",
    "        roa = (net_income / total_assets) * 100 if net_income and total_assets else None\n",
    "        total_investment = market_cap + total_debt if market_cap else None\n",
    "        roi = (net_income / total_investment) * 100 if net_income and total_investment else None\n",
    "\n",
    "        key_metrics = {\n",
    "            \"Stock\": stock,\n",
    "            \"Market Cap\": market_cap,\n",
    "            \"P/E Ratio\": info.get(\"trailingPE\"),\n",
    "            \"Forward P/E\": info.get(\"forwardPE\"),\n",
    "            \"PEG Ratio\": info.get(\"trailingPegRatio\"),\n",
    "            \"P/S Ratio\": info.get(\"priceToSalesTrailing12Months\"),\n",
    "            \"P/B Ratio\": info.get(\"priceToBook\"),\n",
    "            \"EV/EBITDA\": info.get(\"enterpriseToEbitda\"),\n",
    "            \"Debt to Equity\": info.get(\"debtToEquity\"),\n",
    "            \"ROE (%)\": roe,\n",
    "            \"ROA (%)\": roa,\n",
    "            \"ROI (%)\": roi,\n",
    "            \"Gross Margin\": info.get(\"grossMargins\"),\n",
    "            \"Operating Margin\": info.get(\"operatingMargins\"),\n",
    "            \"Profit Margin\": info.get(\"profitMargins\"),\n",
    "            \"Dividend Yield\": info.get(\"dividendYield\"),\n",
    "            \"Beta\": info.get(\"beta\"),\n",
    "        }\n",
    "\n",
    "        def melt_dataframe(df, name):\n",
    "            if df is not None and not df.empty:\n",
    "                df = df.T\n",
    "                df.reset_index(inplace=True)\n",
    "                df.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "                df = df.melt(id_vars=['Metric'], var_name='Date', value_name='Value')\n",
    "                df['Stock'] = stock\n",
    "                return df\n",
    "            return None\n",
    "\n",
    "        return {\n",
    "            \"metrics\": key_metrics,\n",
    "            \"balance_q\": melt_dataframe(balance_sheet_q, \"Balance Sheet Quarterly\"),\n",
    "            \"income_q\": melt_dataframe(income_statement_q, \"Income Statement Quarterly\"),\n",
    "            \"cashflow_q\": melt_dataframe(cashflow_q, \"Cash Flow Quarterly\"),\n",
    "            \"balance_a\": melt_dataframe(balance_sheet_a, \"Balance Sheet Annual\"),\n",
    "            \"income_a\": melt_dataframe(income_statement_a, \"Income Statement Annual\"),\n",
    "            \"cashflow_a\": melt_dataframe(cashflow_a, \"Cash Flow Annual\"),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for {stock}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "all_data = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    all_data = list(executor.map(fetch_fundamental_data, all_stocks))\n",
    "\n",
    "all_data = [d for d in all_data if d]\n",
    "\n",
    "df_metrics = pd.DataFrame([d[\"metrics\"] for d in all_data])\n",
    "df_balance_q = pd.concat([d[\"balance_q\"] for d in all_data if d[\"balance_q\"] is not None], ignore_index=True)\n",
    "df_income_q = pd.concat([d[\"income_q\"] for d in all_data if d[\"income_q\"] is not None], ignore_index=True)\n",
    "df_cashflow_q = pd.concat([d[\"cashflow_q\"] for d in all_data if d[\"cashflow_q\"] is not None], ignore_index=True)\n",
    "df_balance_a = pd.concat([d[\"balance_a\"] for d in all_data if d[\"balance_a\"] is not None], ignore_index=True)\n",
    "df_income_a = pd.concat([d[\"income_a\"] for d in all_data if d[\"income_a\"] is not None], ignore_index=True)\n",
    "df_cashflow_a = pd.concat([d[\"cashflow_a\"] for d in all_data if d[\"cashflow_a\"] is not None], ignore_index=True)\n",
    "\n",
    "df_metrics.to_csv(\"../Data/fundamental/fundamental_metrics.csv\", index=False)\n",
    "df_balance_q.to_csv(\"../Data/fundamental/quarterly_balance_sheet.csv\", index=False)\n",
    "df_income_q.to_csv(\"../Data/fundamental/quarterly_income_statement.csv\", index=False)\n",
    "df_cashflow_q.to_csv(\"../Data/fundamental/quarterly_cashflow.csv\", index=False)\n",
    "df_balance_a.to_csv(\"../Data/fundamental/annual_balance_sheet.csv\", index=False)\n",
    "df_income_a.to_csv(\"../Data/fundamental/annual_income_statement.csv\", index=False)\n",
    "df_cashflow_a.to_csv(\"../Data/fundamental/annual_cashflow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9b35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from google.colab import files\n",
    "\n",
    "# def get_date_range(file_name):\n",
    "#     df = pd.read_csv(file_name)\n",
    "#     if 'Date' in df.columns:\n",
    "#         df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date\n",
    "#         min_date = df['Date'].min()\n",
    "#         max_date = df['Date'].max()\n",
    "\n",
    "#         if 'annual' in file_name.lower():\n",
    "#             years = max_date.year - min_date.year\n",
    "#             if max_date.month > min_date.month:\n",
    "#                 years += 1\n",
    "#             print(f\"{file_name}: {min_date} to {max_date}\")\n",
    "#             print(f\"Years: {years}\")\n",
    "#         elif 'quarterly' in file_name.lower():\n",
    "#             quarters = (max_date.year - min_date.year) * 4 + (max_date.month - 1) // 3 + 1\n",
    "#             print(f\"{file_name}: {min_date} to {max_date}\")\n",
    "#             print(f\"Quarters: {quarters}\")\n",
    "#     else:\n",
    "#         print(f\"No 'Date' column found in {file_name}\")\n",
    "\n",
    "# get_date_range(\"../Data/fundamental/annual_income_statement.csv\")\n",
    "# get_date_range(\"../Data/fundamental/annual_balance_sheet.csv\")\n",
    "# get_date_range(\"../Data/fundamental/annual_cashflow.csv\")\n",
    "# get_date_range(\"../Data/fundamental/quarterly_income_statement.csv\")\n",
    "# get_date_range(\"../Data/fundamental/quarterly_balance_sheet.csv\")\n",
    "# get_date_range(\"../Data/fundamental/quarterly_cashflow.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00d1b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/6mphs8bd5d19hyzf97x081k00000gp/T/ipykernel_56511/3480108562.py:35: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged = df_merged.sort_values(by=[\"Stock\", \"Date\"]).infer_objects(copy=False).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Selecting required features\n",
    "selected_features = [\"Metric\", \"Date\", \"Value\", \"Stock\"]\n",
    "df_income_q = df_income_q[selected_features]\n",
    "df_balance_q = df_balance_q[selected_features]\n",
    "df_cashflow_q = df_cashflow_q[selected_features]\n",
    "\n",
    "# Pivot dataframes\n",
    "df_income_pivot = df_income_q.pivot_table(index=[\"Date\", \"Stock\"], columns=\"Metric\", values=\"Value\").reset_index()\n",
    "df_balance_pivot = df_balance_q.pivot_table(index=[\"Date\", \"Stock\"], columns=\"Metric\", values=\"Value\").reset_index()\n",
    "df_cashflow_pivot = df_cashflow_q.pivot_table(index=[\"Date\", \"Stock\"], columns=\"Metric\", values=\"Value\").reset_index()\n",
    "\n",
    "# Ensure only relevant columns from df_metrics are merged\n",
    "df_metrics_selected = df_metrics[[\"Stock\", \"Market Cap\", \"P/E Ratio\", \"Forward P/E\", \"PEG Ratio\",\n",
    "                                  \"P/S Ratio\", \"P/B Ratio\", \"EV/EBITDA\", \"Debt to Equity\",\n",
    "                                  \"ROE (%)\", \"ROA (%)\", \"ROI (%)\", \"Gross Margin\",\n",
    "                                  \"Operating Margin\", \"Profit Margin\", \"Dividend Yield\", \"Beta\"]]\n",
    "\n",
    "# Merge the fundamental metrics with the financial statements\n",
    "df_merged = df_income_pivot.merge(df_balance_pivot, on=[\"Date\", \"Stock\"], how=\"outer\", suffixes=(\"\", \"_bal\"))\n",
    "df_merged = df_merged.merge(df_cashflow_pivot, on=[\"Date\", \"Stock\"], how=\"outer\", suffixes=(\"\", \"_cf\"))\n",
    "\n",
    "# Merge stock-level metrics (df_metrics) with df_merged on \"Stock\"\n",
    "df_merged = df_merged.merge(df_metrics_selected, on=\"Stock\", how=\"left\")\n",
    "\n",
    "# Sort and fill missing values\n",
    "df_merged = df_merged.sort_values(by=[\"Stock\", \"Date\"]).infer_objects(copy=False).fillna(0)\n",
    "\n",
    "# Scale all numerical columns except \"Stock\" and \"Date\"\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = df_merged.copy()\n",
    "df_scaled.iloc[:, 2:] = scaler.fit_transform(df_scaled.iloc[:, 2:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66468095",
   "metadata": {},
   "source": [
    "# LSTM Quarterly HyperParameter Tuning (Dont run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07187983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 07s]\n",
      "val_loss: 0.022716928273439407\n",
      "\n",
      "Best val_loss So Far: 0.011405902914702892\n",
      "Total elapsed time: 00h 01m 18s\n",
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 1.2622 - val_loss: 0.1049\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1042 - val_loss: 0.0706\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0860 - val_loss: 0.0636\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0847 - val_loss: 0.0623\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - val_loss: 0.0599\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0704 - val_loss: 0.0581\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0713 - val_loss: 0.0549\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0633 - val_loss: 0.0466\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0517 - val_loss: 0.0458\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0408 - val_loss: 0.0747\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0403 - val_loss: 0.0489\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0352 - val_loss: 0.0410\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0317 - val_loss: 0.0377\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0323 - val_loss: 0.0479\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0257 - val_loss: 0.0401\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0243 - val_loss: 0.0463\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0204 - val_loss: 0.0303\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0231 - val_loss: 0.0396\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0175 - val_loss: 0.0262\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0222 - val_loss: 0.0364\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0171 - val_loss: 0.0290\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0132 - val_loss: 0.0275\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0218 - val_loss: 0.0231\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0151 - val_loss: 0.0222\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0156 - val_loss: 0.0263\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - val_loss: 0.0208\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0242\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0187 - val_loss: 0.0239\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0207 - val_loss: 0.0220\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0170 - val_loss: 0.0248\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0135 - val_loss: 0.0327\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0154 - val_loss: 0.0200\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0161 - val_loss: 0.0183\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0249 - val_loss: 0.0161\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0108 - val_loss: 0.0216\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0181 - val_loss: 0.0168\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0136 - val_loss: 0.0215\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0133 - val_loss: 0.0178\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0092 - val_loss: 0.0125\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0075 - val_loss: 0.0124\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - val_loss: 0.0100\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0145 - val_loss: 0.0213\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0192 - val_loss: 0.0261\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0107 - val_loss: 0.0164\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0109 - val_loss: 0.0148\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0082 - val_loss: 0.0127\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0087 - val_loss: 0.0105\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0094 - val_loss: 0.0112\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0086 - val_loss: 0.0104\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0122\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0077 - val_loss: 0.0158\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - val_loss: 0.0102\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0106\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0077 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - val_loss: 0.0126\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0071 - val_loss: 0.0108\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0090 - val_loss: 0.0152\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0070 - val_loss: 0.0087\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0091\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - val_loss: 0.0097\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0101\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0084 - val_loss: 0.0124\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0077 - val_loss: 0.0113\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0085\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0070 - val_loss: 0.0106\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0090\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0091\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037 - val_loss: 0.0076\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0046 - val_loss: 0.0080\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0089\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "   S.No     Company  Predicted_Net_Income\n",
      "0     1        ONGC              0.763531\n",
      "1     2   COALINDIA              0.412506\n",
      "2     3    HDFCBANK              0.390312\n",
      "3     4   TATASTEEL              0.383524\n",
      "4     5        SBIN              0.383358\n",
      "5     6  BANKBARODA              0.367085\n",
      "6     7         PNB              0.353950\n",
      "7     8  BHARTIARTL              0.292195\n",
      "8     9    AXISBANK              0.210136\n",
      "9    10    JSWSTEEL              0.173945\n",
      "Total Training Time: 12.23 seconds\n",
      "Total Prediction Time: 0.43 seconds\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def create_sequences(data, stock_col, target_col, seq_length=4):\n",
    "    sequences, labels, stocks = [], [], []\n",
    "    for stock in data[stock_col].unique():\n",
    "        stock_data = data[data[stock_col] == stock].drop(columns=[stock_col, \"Date\"]).values\n",
    "        if len(stock_data) > seq_length:\n",
    "            for i in range(len(stock_data) - seq_length):\n",
    "                sequences.append(stock_data[i:i+seq_length])\n",
    "                labels.append(stock_data[i+seq_length, target_col])\n",
    "                stocks.append(stock)\n",
    "    return np.array(sequences), np.array(labels), stocks\n",
    "\n",
    "X, y, stock_list = create_sequences(df_scaled, \"Stock\", target_col=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test, stock_train, stock_test = train_test_split(\n",
    "    X, y, stock_list, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "    # First BiLSTM layer\n",
    "    model.add(Bidirectional(LSTM(hp.Int('bilstm_units_1', min_value=32, max_value=128, step=32), return_sequences=True)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Second BiLSTM layer\n",
    "    model.add(Bidirectional(LSTM(hp.Int('bilstm_units_2', min_value=32, max_value=128, step=32))))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                  loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='../Data/fundamental/hyperparameter_tuning',\n",
    "    project_name='lstm_stock_prediction'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "start_train = time.time()\n",
    "best_model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "end_train = time.time()\n",
    "training_time = end_train - start_train\n",
    "\n",
    "start_pred = time.time()\n",
    "predictions = best_model.predict(X_test)\n",
    "end_pred = time.time()\n",
    "prediction_time = end_pred - start_pred\n",
    "\n",
    "def rank_top_stocks(preds, stocks, top_n=10):\n",
    "    stock_preds = pd.DataFrame({\"Stock\": stocks, \"Predicted_Net_Income\": preds.flatten()})\n",
    "    stock_preds[\"Company\"] = stock_preds[\"Stock\"].str.replace(r'\\.NS|\\.BO', '', regex=True)\n",
    "    stock_avg_preds = stock_preds.groupby(\"Company\", as_index=False)[\"Predicted_Net_Income\"].mean()\n",
    "    ranked_stocks = stock_avg_preds.sort_values(by=\"Predicted_Net_Income\", ascending=False).head(top_n).reset_index(drop=True)\n",
    "    ranked_stocks.index += 1\n",
    "    ranked_stocks.reset_index(inplace=True)\n",
    "    ranked_stocks.rename(columns={\"index\": \"S.No\"}, inplace=True)\n",
    "    return ranked_stocks\n",
    "\n",
    "top_stocks = rank_top_stocks(predictions, stock_test)\n",
    "print(top_stocks)\n",
    "print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
    "print(f\"Total Prediction Time: {prediction_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e3114",
   "metadata": {},
   "source": [
    "# Bi-LSTM Quarterly model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d192d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.7207 - val_loss: 0.1653\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0711 - val_loss: 0.0223\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0533 - val_loss: 0.0179\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0307 - val_loss: 0.0148\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0295 - val_loss: 0.0199\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0284 - val_loss: 0.0145\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0267 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0255 - val_loss: 0.0117\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0237 - val_loss: 0.0112\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0217 - val_loss: 0.0109\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0212 - val_loss: 0.0103\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0188 - val_loss: 0.0106\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0187 - val_loss: 0.0094\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0188 - val_loss: 0.0092\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0191 - val_loss: 0.0093\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0211 - val_loss: 0.0101\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0200 - val_loss: 0.0093\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0158 - val_loss: 0.0080\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0150 - val_loss: 0.0076\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0142 - val_loss: 0.0073\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0142 - val_loss: 0.0073\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0088 - val_loss: 0.0036\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 7.8768e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 8.3807e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 9.2612e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 7.6196e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 9.3559e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 5.7521e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 5.9839e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.6818e-04 - val_loss: 4.8037e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 9.4682e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 7.6144e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.6565e-04 - val_loss: 0.0011\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 8.2794e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 5.1583e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.9359e-04 - val_loss: 6.9054e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 9.9286e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 9.9694e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.7483e-04 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 5.9401e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.7817e-04 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 7.2949e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 3.6923e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.7237e-04 - val_loss: 7.1355e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.8043e-04 - val_loss: 3.5536e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.0268e-04 - val_loss: 0.0012\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 9.0203e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 6.3979e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 3.7257e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 8.1690e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.9153e-04 - val_loss: 7.3135e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.9993e-04 - val_loss: 4.4440e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.7784e-04 - val_loss: 4.7905e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.3633e-04 - val_loss: 2.9037e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.2753e-04 - val_loss: 4.0056e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 7.2097e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.0261e-04 - val_loss: 6.2899e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.9850e-04 - val_loss: 0.0026\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 7.0430e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 9.2962e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.1633e-04 - val_loss: 3.5493e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 8.2242e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "   S.No     Company  Predicted_Net_Income\n",
      "0     1   BRITANNIA              0.586954\n",
      "1     2   COALINDIA              0.429983\n",
      "2     3  BHARTIARTL              0.371957\n",
      "3     4         ITC              0.346446\n",
      "4     5  BAJAJ-AUTO              0.286892\n",
      "5     6   EICHERMOT              0.280245\n",
      "6     7  HINDUNILVR              0.273297\n",
      "7     8  BAJFINANCE              0.239618\n",
      "8     9       CIPLA              0.231883\n",
      "9    10  ASIANPAINT              0.227434\n",
      "Total Training Time: 13.06 seconds\n",
      "Total Prediction Time: 0.41 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to create sequences for LSTM input\n",
    "def create_sequences(data, stock_col, target_col, seq_length=4):\n",
    "    sequences, labels, stocks = [], [], []\n",
    "    for stock in data[stock_col].unique():\n",
    "        stock_data = data[data[stock_col] == stock].drop(columns=[stock_col, \"Date\"]).values\n",
    "        if len(stock_data) > seq_length:\n",
    "            for i in range(len(stock_data) - seq_length):\n",
    "                sequences.append(stock_data[i:i+seq_length])\n",
    "                labels.append(stock_data[i+seq_length, target_col])\n",
    "                stocks.append(stock)\n",
    "    return np.array(sequences), np.array(labels), stocks\n",
    "\n",
    "X, y, stock_list = create_sequences(df_scaled, \"Stock\", target_col=285)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, stock_train, stock_test = train_test_split(\n",
    "    X, y, stock_list, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Define BiLSTM model\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Bidirectional(LSTM(96, return_sequences=True)),  # BiLSTM layer 1\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(96)),  # BiLSTM layer 2\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.004201765072917902), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "start_train = time.time()\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "end_train = time.time()\n",
    "training_time = end_train - start_train\n",
    "\n",
    "# Make predictions\n",
    "start_pred = time.time()\n",
    "predictions = model.predict(X_test)\n",
    "end_pred = time.time()\n",
    "prediction_time = end_pred - start_pred\n",
    "\n",
    "# Rank top stocks based on predictions\n",
    "def rank_top_stocks(preds, stocks, top_n=10):\n",
    "    stock_preds = pd.DataFrame({\"Stock\": stocks, \"Predicted_Net_Income\": preds.flatten()})\n",
    "    stock_preds[\"Company\"] = stock_preds[\"Stock\"].str.replace(r'\\.NS|\\.BO', '', regex=True)\n",
    "    stock_avg_preds = stock_preds.groupby(\"Company\", as_index=False)[\"Predicted_Net_Income\"].mean()\n",
    "    ranked_stocks = stock_avg_preds.sort_values(by=\"Predicted_Net_Income\", ascending=False).head(top_n).reset_index(drop=True)\n",
    "    ranked_stocks.index += 1\n",
    "    ranked_stocks.reset_index(inplace=True)\n",
    "    ranked_stocks.rename(columns={\"index\": \"S.No\"}, inplace=True)\n",
    "    return ranked_stocks[[\"S.No\", \"Company\", \"Predicted_Net_Income\"]]\n",
    "\n",
    "# Get top ranked stocks\n",
    "top_stocks = rank_top_stocks(predictions, stock_test)\n",
    "print(top_stocks)\n",
    "\n",
    "# Print training and prediction times\n",
    "print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
    "print(f\"Total Prediction Time: {prediction_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Company</th>\n",
       "      <th>Predicted_Net_Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BRITANNIA</td>\n",
       "      <td>0.586954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>COALINDIA</td>\n",
       "      <td>0.429983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BHARTIARTL</td>\n",
       "      <td>0.371957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ITC</td>\n",
       "      <td>0.346446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BAJAJ-AUTO</td>\n",
       "      <td>0.286892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>EICHERMOT</td>\n",
       "      <td>0.280245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>HINDUNILVR</td>\n",
       "      <td>0.273297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>BAJFINANCE</td>\n",
       "      <td>0.239618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>CIPLA</td>\n",
       "      <td>0.231883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ASIANPAINT</td>\n",
       "      <td>0.227434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No     Company  Predicted_Net_Income\n",
       "0     1   BRITANNIA              0.586954\n",
       "1     2   COALINDIA              0.429983\n",
       "2     3  BHARTIARTL              0.371957\n",
       "3     4         ITC              0.346446\n",
       "4     5  BAJAJ-AUTO              0.286892\n",
       "5     6   EICHERMOT              0.280245\n",
       "6     7  HINDUNILVR              0.273297\n",
       "7     8  BAJFINANCE              0.239618\n",
       "8     9       CIPLA              0.231883\n",
       "9    10  ASIANPAINT              0.227434"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "start_pred = time.time()\n",
    "predictions = model.predict(X_test)\n",
    "end_pred = time.time()\n",
    "prediction_time = end_pred - start_pred\n",
    "\n",
    "def rank_top_stocks(preds, stocks, top_n=10):\n",
    "    stock_preds = pd.DataFrame({\"Stock\": stocks, \"Predicted_Net_Income\": preds.flatten()})\n",
    "    stock_preds[\"Company\"] = stock_preds[\"Stock\"].str.replace(r'\\.NS|\\.BO', '', regex=True)\n",
    "    stock_avg_preds = stock_preds.groupby(\"Company\", as_index=False)[\"Predicted_Net_Income\"].mean()\n",
    "    ranked_stocks = stock_avg_preds.sort_values(by=\"Predicted_Net_Income\", ascending=False).head(top_n).reset_index(drop=True)\n",
    "    ranked_stocks.index += 1\n",
    "    ranked_stocks.reset_index(inplace=True)\n",
    "    ranked_stocks.rename(columns={\"index\": \"S.No\"}, inplace=True)\n",
    "    return ranked_stocks[[\"S.No\", \"Company\", \"Predicted_Net_Income\"]]\n",
    "\n",
    "top_stocks = rank_top_stocks(predictions, stock_test)\n",
    "top_stocks.to_csv(\"../Data/fundamental/top_stocks.csv\", index=False)\n",
    "top_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06e33556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Time: 13.06 seconds\n",
      "Total Prediction Time: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
    "print(f\"Total Prediction Time: {prediction_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfab1801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation:\n",
      "Mean Absolute Error (MAE): 0.02384786597759315\n",
      "Root Mean Squared Error (RMSE): 0.028677821135479564\n",
      "Mean Absolute Percentage Error (MAPE): 27.19%\n",
      "R² Score: 0.9343213767716119\n",
      "Explained Variance Score: 0.9500109729499081\n",
      "\n",
      "Model Fit Interpretation: Excellent Model Fit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error, explained_variance_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "explained_var = explained_variance_score(y_test, predictions)\n",
    "\n",
    "print(f\"Model Evaluation:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape * 100:.2f}%\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "print(f\"Explained Variance Score: {explained_var}\")\n",
    "\n",
    "def interpret_r2_score(r2):\n",
    "    if r2 >= 0.9:\n",
    "        return \"Excellent Model Fit\"\n",
    "    elif r2 >= 0.75:\n",
    "        return \"Good Model Fit\"\n",
    "    elif r2 >= 0.5:\n",
    "        return \"Moderate Model Fit\"\n",
    "    else:\n",
    "        return \"Poor Model Fit - Consider Improving\"\n",
    "\n",
    "print(f\"\\nModel Fit Interpretation: {interpret_r2_score(r2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
