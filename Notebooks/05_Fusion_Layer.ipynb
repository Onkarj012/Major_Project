{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91e3ec-6fd9-4272-9028-43d7d33e44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/FUSION_offline_notebook.py\n",
    "# Combine embeddings from 3 trained models (ResNLS, GRU, SCSO-LSTM) and train a fusion head\n",
    "\n",
    "import os, math, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "# DATA_CSV = \"data/HDFCBANK.NS.csv\"           # path to your CSV\n",
    "data_dir = \"../Data\"  # path where your CSVs are stored\n",
    "ticker = 'HDFCBANK.NS'\n",
    "DATA_CSV = os.path.join(data_dir, f\"{ticker}_features.csv\")\n",
    "TARGET = \"Close\"                             # predict next Close\n",
    "VAL_FRAC = 0.15\n",
    "TEST_FRAC = 0.15\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# paths to saved trained models (from your individual notebooks)\n",
    "RESNLS_PATH = \"models/resnls_best.keras\"     # saved Keras model with 'resnls_embedding' layer\n",
    "GRU_PATH    = \"models/gru_best.keras\"        # saved Keras model with 'gru_embedding' layer\n",
    "SCSO_PATH   = \"models/scso_lstm_best.keras\"  # saved Keras model; if no named embedding, we take penultimate\n",
    "\n",
    "# respective window sizes used during training\n",
    "RESNLS_SEQ = 5\n",
    "GRU_SEQ    = 20\n",
    "SCSO_SEQ   = 90\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Load and feature prep (same as your backbones)\n",
    "# -----------------------------\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    k = 2 / (span + 1)\n",
    "    return series.ewm(alpha=k, adjust=False).mean()\n",
    "\n",
    "def wilder_ema(series: pd.Series, period: int) -> pd.Series:\n",
    "    return series.ewm(alpha=1/period, adjust=False).mean()\n",
    "\n",
    "def rsi_wilder(close: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    avg_up = wilder_ema(up, period)\n",
    "    avg_down = wilder_ema(down, period)\n",
    "    rs = avg_up / (avg_down.replace(0, np.nan))\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi.fillna(0)\n",
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "cols = {c: c.title() for c in df.columns}\n",
    "df.rename(columns=cols, inplace=True)\n",
    "df = df[['Open','High','Low','Close','Volume']].dropna().reset_index(drop=True)\n",
    "\n",
    "features = df.copy()\n",
    "features['LogRet'] = np.log(features['Close']).diff().fillna(0.0)\n",
    "features['RSI14']  = rsi_wilder(features['Close'], 14)\n",
    "features['SMA10']  = features['Close'].rolling(10).mean().bfill()\n",
    "features['SMA20']  = features['Close'].rolling(20).mean().bfill()\n",
    "features['SMA50']  = features['Close'].rolling(50).mean().bfill()\n",
    "features['SMA100'] = features['Close'].rolling(100).mean().bfill()\n",
    "features = features.dropna().reset_index(drop=True)\n",
    "\n",
    "# predict next-step Close\n",
    "target = features[TARGET].shift(-1).dropna().reset_index(drop=True)\n",
    "features = features.iloc[:-1, :].reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Chronological split\n",
    "# -----------------------------\n",
    "n = len(features)\n",
    "test_size = int(math.floor(TEST_FRAC * n))\n",
    "val_size  = int(math.floor(VAL_FRAC * n))\n",
    "train_size = n - val_size - test_size\n",
    "\n",
    "X_all = features.values\n",
    "y_all = target.values.reshape(-1, 1)\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_raw = X_all[:train_size]\n",
    "X_val_raw   = X_all[train_size:train_size+val_size]\n",
    "X_test_raw  = X_all[train_size+val_size:]\n",
    "\n",
    "y_train_raw = y_all[:train_size]\n",
    "y_val_raw   = y_all[train_size:train_size+val_size]\n",
    "y_test_raw  = y_all[train_size+val_size:]\n",
    "\n",
    "X_train_s = scaler_X.fit_transform(X_train_raw)\n",
    "X_val_s   = scaler_X.transform(X_val_raw)\n",
    "X_test_s  = scaler_X.transform(X_test_raw)\n",
    "\n",
    "y_train_s = scaler_y.fit_transform(y_train_raw)\n",
    "y_val_s   = scaler_y.transform(y_val_raw)\n",
    "y_test_s  = scaler_y.transform(y_test_raw)\n",
    "\n",
    "def make_sequences_with_end_idx(X, y, seq_len):\n",
    "    Xs, ys, end_idx = [], [], []\n",
    "    for i in range(len(X) - seq_len + 1):\n",
    "        Xs.append(X[i:i+seq_len])\n",
    "        ys.append(y[i+seq_len-1])\n",
    "        end_idx.append(i+seq_len-1)  # index in this split\n",
    "    return np.array(Xs), np.array(ys), np.array(end_idx)\n",
    "\n",
    "# Build sequences per branch on each split (train, val, test)\n",
    "def build_branch_sequences(seq_len):\n",
    "    Xtr, ytr, idx_tr = make_sequences_with_end_idx(X_train_s, y_train_s, seq_len)\n",
    "    Xva, yva, idx_va = make_sequences_with_end_idx(\n",
    "        np.vstack([X_train_s[-(seq_len-1):], X_val_s]),\n",
    "        np.vstack([y_train_s[-(seq_len-1):], y_val_s]),\n",
    "        seq_len\n",
    "    )\n",
    "    # map val end_idx to global indices\n",
    "    idx_va_global = (train_size - (seq_len-1)) + idx_va\n",
    "    Xte, yte, idx_te = make_sequences_with_end_idx(\n",
    "        np.vstack([X_val_s[-(seq_len-1):], X_test_s]),\n",
    "        np.vstack([y_val_s[-(seq_len-1):], y_test_s]),\n",
    "        seq_len\n",
    "    )\n",
    "    idx_te_global = (train_size + val_size - (seq_len-1)) + idx_te\n",
    "    return (Xtr, ytr, idx_tr), (Xva, yva, idx_va_global), (Xte, yte, idx_te_global)\n",
    "\n",
    "res_tr, res_va, res_te = build_branch_sequences(RESNLS_SEQ)\n",
    "gru_tr, gru_va, gru_te = build_branch_sequences(GRU_SEQ)\n",
    "lstm_tr, lstm_va, lstm_te = build_branch_sequences(SCSO_SEQ)\n",
    "\n",
    "# -----------------------------\n",
    "# Load trained models and build embedding models\n",
    "# -----------------------------\n",
    "res_model = tf.keras.models.load_model(RESNLS_PATH, compile=False)\n",
    "gru_model = tf.keras.models.load_model(GRU_PATH, compile=False)\n",
    "lstm_model= tf.keras.models.load_model(SCSO_PATH, compile=False)\n",
    "\n",
    "# Extract embeddings via named layer if present, else via penultimate layer\n",
    "def build_embedding_model(m, preferred_layer_name):\n",
    "    try:\n",
    "        out = m.get_layer(preferred_layer_name).output\n",
    "        return Model(m.input, out)\n",
    "    except:\n",
    "        # fallback: second-to-last layer output\n",
    "        out = m.layers[-2].output\n",
    "        return Model(m.input, out)\n",
    "\n",
    "res_embed = build_embedding_model(res_model, \"resnls_embedding\")\n",
    "gru_embed = build_embedding_model(gru_model, \"gru_embedding\")\n",
    "lstm_embed= build_embedding_model(lstm_model, \"lstm_embedding\")  # may fallback\n",
    "\n",
    "# -----------------------------\n",
    "# Align by global end indices (intersection across branches)\n",
    "# -----------------------------\n",
    "def align_by_indices(idx_a, idx_b, idx_c):\n",
    "    common = np.intersect1d(np.intersect1d(idx_a, idx_b), idx_c)\n",
    "    def selector(idx_vec):\n",
    "        where = {v:i for i,v in enumerate(idx_vec)}\n",
    "        return np.array([where[v] for v in common])\n",
    "    return common, selector\n",
    "\n",
    "# Selectors for each split\n",
    "common_tr, sel_tr = align_by_indices(res_tr[2], gru_tr[2], lstm_tr[2])\n",
    "common_va, sel_va = align_by_indices(res_va[2], gru_va[2], lstm_va[2])\n",
    "common_te, sel_te = align_by_indices(res_te[2], gru_te[2], lstm_te[2])\n",
    "\n",
    "# Slice aligned sequences\n",
    "Xtr_res = res_tr[0][sel_tr(res_tr[2])]\n",
    "Xtr_gru = gru_tr[0][sel_tr(gru_tr[2])]\n",
    "Xtr_lstm= lstm_tr[0][sel_tr(lstm_tr[2])]\n",
    "ytr     = res_tr[1][sel_tr(res_tr[2])]\n",
    "\n",
    "Xva_res = res_va[0][sel_va(res_va[2])]\n",
    "Xva_gru = gru_va[0][sel_va(gru_va[2])]\n",
    "Xva_lstm= lstm_va[0][sel_va(lstm_va[2])]\n",
    "yva     = res_va[1][sel_va(res_va[2])]\n",
    "\n",
    "Xte_res = res_te[0][sel_te(res_te[2])]\n",
    "Xte_gru = gru_te[0][sel_te(gru_te[2])]\n",
    "Xte_lstm= lstm_te[0][sel_te(lstm_te[2])]\n",
    "yte     = res_te[1][sel_te(res_te[2])]\n",
    "\n",
    "# -----------------------------\n",
    "# Compute embeddings for each branch\n",
    "# -----------------------------\n",
    "Etr_res = res_embed.predict(Xtr_res, batch_size=256, verbose=0)\n",
    "Etr_gru = gru_embed.predict(Xtr_gru, batch_size=256, verbose=0)\n",
    "Etr_lstm= lstm_embed.predict(Xtr_lstm, batch_size=256, verbose=0)\n",
    "\n",
    "Eva_res = res_embed.predict(Xva_res, batch_size=256, verbose=0)\n",
    "Eva_gru = gru_embed.predict(Xva_gru, batch_size=256, verbose=0)\n",
    "Eva_lstm= lstm_embed.predict(Xva_lstm, batch_size=256, verbose=0)\n",
    "\n",
    "Ete_res = res_embed.predict(Xte_res, batch_size=256, verbose=0)\n",
    "Ete_gru = gru_embed.predict(Xte_gru, batch_size=256, verbose=0)\n",
    "Ete_lstm= lstm_embed.predict(Xte_lstm, batch_size=256, verbose=0)\n",
    "\n",
    "# Concatenate embeddings\n",
    "Xtr_fuse = np.concatenate([Etr_res, Etr_gru, Etr_lstm], axis=1)\n",
    "Xva_fuse = np.concatenate([Eva_res, Eva_gru, Eva_lstm], axis=1)\n",
    "Xte_fuse = np.concatenate([Ete_res, Ete_gru, Ete_lstm], axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Fusion head (MLP)\n",
    "# -----------------------------\n",
    "inp = layers.Input(shape=(Xtr_fuse.shape[1],))\n",
    "x = layers.Dense(128, activation='relu')(inp)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "out = layers.Dense(1, activation='linear')(x)\n",
    "fusion = Model(inp, out)\n",
    "fusion.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "\n",
    "cbs = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "hist = fusion.fit(Xtr_fuse, ytr, validation_data=(Xva_fuse, yva), epochs=100, batch_size=128, callbacks=cbs, verbose=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate and plot\n",
    "# -----------------------------\n",
    "y_pred_s = fusion.predict(Xte_fuse, batch_size=256)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_s)\n",
    "y_true = scaler_y.inverse_transform(yte)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(f\"Fusion MSE={mse:.6f}  RMSE={rmse:.6f}  MAE={mae:.6f}\")\n",
    "\n",
    "# Build time index for aligned test targets\n",
    "# We built end indices in global space; we can just use a simple sequential index for plotting\n",
    "plot_idx = np.arange(len(y_true))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(plot_idx, y_true.flatten(), label=\"Actual\", color='black', linewidth=1.5)\n",
    "plt.plot(plot_idx, y_pred.flatten(), label=\"Predicted\", color='purple', linewidth=1.5)\n",
    "plt.title(\"Fusion Head: Actual vs Predicted Close\")\n",
    "plt.xlabel(\"Aligned Test Samples\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5086d-bb60-42ef-b4a0-12965c17735a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
